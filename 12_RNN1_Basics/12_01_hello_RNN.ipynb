{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture 12: RNN1 - Basics"
      ],
      "metadata": {
        "id": "3f7WrohgRPr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import sys"
      ],
      "metadata": {
        "id": "LxKQHEZdS7pG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(777)  # reproducibility"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IxYkVqqdOWe",
        "outputId": "219e629b-0291-4908-8c4e-6af99f1b4783"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa66dca2f90>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (1) Data preparation"
      ],
      "metadata": {
        "id": "ka31MQ9NSQdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx2char = ['h', 'i', 'e', 'l', 'o']\n",
        "\n",
        "# Teach \"hihell\" -> \"ihello\"\n",
        "x_data = [[0, 1, 0, 2, 3, 3]] # \"hihell\"\n",
        "one_hot_lookup = [[[1, 0, 0, 0, 0],  # 0\n",
        "                   [0, 1, 0, 0, 0],  # 1\n",
        "                   [0, 0, 1, 0, 0],  # 2\n",
        "                   [0, 0, 0, 1, 0],  # 3\n",
        "                   [0, 0, 0, 0, 1]]] # 4\n",
        "\n",
        "y_data = [1, 0, 2, 3, 3, 4] # \"ihello\"\n",
        "x_one_hot = [[one_hot_lookup[0][x] for x in x_data[0]]]\n",
        "\n",
        "# As we have one batch of samples, we will change them to variables only once\n",
        "inputs = Variable(torch.Tensor(x_one_hot))\n",
        "labels = Variable(torch.LongTensor(y_data))"
      ],
      "metadata": {
        "id": "FXdds3UMRPd7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-RmAZaZjZxM",
        "outputId": "5af42658-9695-4e20-fc82-609882a7dc44"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[[1, 0, 0, 0, 0],\n",
              "  [0, 1, 0, 0, 0],\n",
              "  [1, 0, 0, 0, 0],\n",
              "  [0, 0, 1, 0, 0],\n",
              "  [0, 0, 0, 1, 0],\n",
              "  [0, 0, 0, 1, 0]]]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (2) Parameters"
      ],
      "metadata": {
        "id": "1rsR4EZHSa9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 5\n",
        "input_size = 5      # one-hot size\n",
        "hidden_size = 5     # ouput from the LSTM. 5 to directly predict one-hot\n",
        "batch_size = 1      # one sentence\n",
        "sequence_length = 6 # |ihello| == 6\n",
        "num_layers = 1      # one-layer rnn"
      ],
      "metadata": {
        "id": "ZLGsp7ZzSa2P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (3) Our model"
      ],
      "metadata": {
        "id": "4_maaxIDS1ER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.sequence_length = sequence_length\n",
        "\n",
        "        self.rnn = nn.RNN(input_size=self.input_size,\n",
        "                          hidden_size=self.hidden_size, batch_first=True)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        hidden = self.init_hidden(x)\n",
        "        \n",
        "        # Reshape input in (batch_size, sequence_length, input_size)\n",
        "        x.view(x.size(0), self.sequence_length, self.input_size)\n",
        "\n",
        "        # Propagate input through RNN\n",
        "        # Input: (batch, seq_len, input_size)\n",
        "        # hidden: (num_layers * num_directions, batch, hidden_size)\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        out = out.view(-1, num_classes)\n",
        "        return out\n",
        "\n",
        "    def init_hidden(self, x):\n",
        "        # Initialize hidden and cell states\n",
        "        # (num_layers * num_directions, batch, hidden_size) for batch_first=True\n",
        "        return Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))"
      ],
      "metadata": {
        "id": "_bmv-dhZSSel"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (4) Loss & Training"
      ],
      "metadata": {
        "id": "jihOCG9hUHpp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ln67bq8LN5X",
        "outputId": "1631af8a-48b6-4c6f-c1fa-1b47954de98a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (rnn): RNN(5, 5, batch_first=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Instantiate RNN model\n",
        "model = Model(num_classes, input_size, hidden_size, num_layers)\n",
        "print(model)\n",
        "\n",
        "# Set loss and optimizer function\n",
        "# CrossEntropyLoss = LogSoftmax + NLLLoss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "epochs = 100\n",
        "for epoch in range(1, epochs + 1):\n",
        "    outputs = model(inputs)\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    _, idx = outputs.max(1)\n",
        "    idx = idx.data.numpy()\n",
        "    result_str = \"\".join([idx2char[c] for c in idx.squeeze()])\n",
        "    print(f\"Epoch: {epoch}, Loss: {loss.data.item()}\")\n",
        "    print(f\"Predicted string: {result_str}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RX8V5XGHUexi",
        "outputId": "e28523d6-203d-44a8-bfe7-c8e72792c199"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 1.6925097703933716\n",
            "Predicted string: llllll\n",
            "Epoch: 2, Loss: 1.522877812385559\n",
            "Predicted string: llllll\n",
            "Epoch: 3, Loss: 1.3925014734268188\n",
            "Predicted string: llllll\n",
            "Epoch: 4, Loss: 1.2628616094589233\n",
            "Predicted string: llllll\n",
            "Epoch: 5, Loss: 1.146023154258728\n",
            "Predicted string: llllll\n",
            "Epoch: 6, Loss: 1.0545097589492798\n",
            "Predicted string: lhelll\n",
            "Epoch: 7, Loss: 1.0023081302642822\n",
            "Predicted string: ihelll\n",
            "Epoch: 8, Loss: 0.9645199179649353\n",
            "Predicted string: ihelll\n",
            "Epoch: 9, Loss: 0.9128332138061523\n",
            "Predicted string: ihelll\n",
            "Epoch: 10, Loss: 0.878986120223999\n",
            "Predicted string: ihelll\n",
            "Epoch: 11, Loss: 0.8401041626930237\n",
            "Predicted string: ihelll\n",
            "Epoch: 12, Loss: 0.8045098781585693\n",
            "Predicted string: ihello\n",
            "Epoch: 13, Loss: 0.7793033719062805\n",
            "Predicted string: ihello\n",
            "Epoch: 14, Loss: 0.7583827972412109\n",
            "Predicted string: ihello\n",
            "Epoch: 15, Loss: 0.738359272480011\n",
            "Predicted string: ihello\n",
            "Epoch: 16, Loss: 0.717498242855072\n",
            "Predicted string: ihello\n",
            "Epoch: 17, Loss: 0.6939412951469421\n",
            "Predicted string: ihello\n",
            "Epoch: 18, Loss: 0.6671566367149353\n",
            "Predicted string: ihelll\n",
            "Epoch: 19, Loss: 0.6433965563774109\n",
            "Predicted string: ihelll\n",
            "Epoch: 20, Loss: 0.6465815901756287\n",
            "Predicted string: ihelll\n",
            "Epoch: 21, Loss: 0.6280152797698975\n",
            "Predicted string: ihelll\n",
            "Epoch: 22, Loss: 0.6069170832633972\n",
            "Predicted string: ihelll\n",
            "Epoch: 23, Loss: 0.5998645424842834\n",
            "Predicted string: ihelll\n",
            "Epoch: 24, Loss: 0.5960835814476013\n",
            "Predicted string: ihello\n",
            "Epoch: 25, Loss: 0.5907202363014221\n",
            "Predicted string: ihello\n",
            "Epoch: 26, Loss: 0.5830585360527039\n",
            "Predicted string: ihello\n",
            "Epoch: 27, Loss: 0.5731964707374573\n",
            "Predicted string: ihello\n",
            "Epoch: 28, Loss: 0.5617813467979431\n",
            "Predicted string: ihello\n",
            "Epoch: 29, Loss: 0.550460159778595\n",
            "Predicted string: ihello\n",
            "Epoch: 30, Loss: 0.5400136113166809\n",
            "Predicted string: ihello\n",
            "Epoch: 31, Loss: 0.526947557926178\n",
            "Predicted string: ihello\n",
            "Epoch: 32, Loss: 0.5244584679603577\n",
            "Predicted string: ihello\n",
            "Epoch: 33, Loss: 0.5295900106430054\n",
            "Predicted string: ihello\n",
            "Epoch: 34, Loss: 0.5194144248962402\n",
            "Predicted string: ihello\n",
            "Epoch: 35, Loss: 0.5069915652275085\n",
            "Predicted string: ihello\n",
            "Epoch: 36, Loss: 0.5032504796981812\n",
            "Predicted string: ihello\n",
            "Epoch: 37, Loss: 0.5025461316108704\n",
            "Predicted string: ihello\n",
            "Epoch: 38, Loss: 0.49961233139038086\n",
            "Predicted string: ihello\n",
            "Epoch: 39, Loss: 0.4961376488208771\n",
            "Predicted string: ihello\n",
            "Epoch: 40, Loss: 0.4943861663341522\n",
            "Predicted string: ihello\n",
            "Epoch: 41, Loss: 0.49349114298820496\n",
            "Predicted string: ihello\n",
            "Epoch: 42, Loss: 0.4917048513889313\n",
            "Predicted string: ihello\n",
            "Epoch: 43, Loss: 0.4883430004119873\n",
            "Predicted string: ihello\n",
            "Epoch: 44, Loss: 0.4840817153453827\n",
            "Predicted string: ihello\n",
            "Epoch: 45, Loss: 0.48125889897346497\n",
            "Predicted string: ihello\n",
            "Epoch: 46, Loss: 0.48129820823669434\n",
            "Predicted string: ihello\n",
            "Epoch: 47, Loss: 0.4798150360584259\n",
            "Predicted string: ihello\n",
            "Epoch: 48, Loss: 0.4765954911708832\n",
            "Predicted string: ihello\n",
            "Epoch: 49, Loss: 0.4760848581790924\n",
            "Predicted string: ihello\n",
            "Epoch: 50, Loss: 0.4764440953731537\n",
            "Predicted string: ihello\n",
            "Epoch: 51, Loss: 0.4753481447696686\n",
            "Predicted string: ihello\n",
            "Epoch: 52, Loss: 0.4732905924320221\n",
            "Predicted string: ihello\n",
            "Epoch: 53, Loss: 0.47238674759864807\n",
            "Predicted string: ihello\n",
            "Epoch: 54, Loss: 0.47226682305336\n",
            "Predicted string: ihello\n",
            "Epoch: 55, Loss: 0.4705854654312134\n",
            "Predicted string: ihello\n",
            "Epoch: 56, Loss: 0.4694715440273285\n",
            "Predicted string: ihello\n",
            "Epoch: 57, Loss: 0.46944379806518555\n",
            "Predicted string: ihello\n",
            "Epoch: 58, Loss: 0.46906721591949463\n",
            "Predicted string: ihello\n",
            "Epoch: 59, Loss: 0.4680730402469635\n",
            "Predicted string: ihello\n",
            "Epoch: 60, Loss: 0.46742498874664307\n",
            "Predicted string: ihello\n",
            "Epoch: 61, Loss: 0.4674821197986603\n",
            "Predicted string: ihello\n",
            "Epoch: 62, Loss: 0.4668675661087036\n",
            "Predicted string: ihello\n",
            "Epoch: 63, Loss: 0.46605241298675537\n",
            "Predicted string: ihello\n",
            "Epoch: 64, Loss: 0.4658510684967041\n",
            "Predicted string: ihello\n",
            "Epoch: 65, Loss: 0.4655487537384033\n",
            "Predicted string: ihello\n",
            "Epoch: 66, Loss: 0.46486544609069824\n",
            "Predicted string: ihello\n",
            "Epoch: 67, Loss: 0.4643840491771698\n",
            "Predicted string: ihello\n",
            "Epoch: 68, Loss: 0.46429112553596497\n",
            "Predicted string: ihello\n",
            "Epoch: 69, Loss: 0.46386095881462097\n",
            "Predicted string: ihello\n",
            "Epoch: 70, Loss: 0.46340879797935486\n",
            "Predicted string: ihello\n",
            "Epoch: 71, Loss: 0.4632895290851593\n",
            "Predicted string: ihello\n",
            "Epoch: 72, Loss: 0.46307095885276794\n",
            "Predicted string: ihello\n",
            "Epoch: 73, Loss: 0.4626671373844147\n",
            "Predicted string: ihello\n",
            "Epoch: 74, Loss: 0.4624299108982086\n",
            "Predicted string: ihello\n",
            "Epoch: 75, Loss: 0.4622892439365387\n",
            "Predicted string: ihello\n",
            "Epoch: 76, Loss: 0.46193623542785645\n",
            "Predicted string: ihello\n",
            "Epoch: 77, Loss: 0.4616661071777344\n",
            "Predicted string: ihello\n",
            "Epoch: 78, Loss: 0.46152010560035706\n",
            "Predicted string: ihello\n",
            "Epoch: 79, Loss: 0.4612671434879303\n",
            "Predicted string: ihello\n",
            "Epoch: 80, Loss: 0.46099260449409485\n",
            "Predicted string: ihello\n",
            "Epoch: 81, Loss: 0.46085262298583984\n",
            "Predicted string: ihello\n",
            "Epoch: 82, Loss: 0.46066930890083313\n",
            "Predicted string: ihello\n",
            "Epoch: 83, Loss: 0.4604281485080719\n",
            "Predicted string: ihello\n",
            "Epoch: 84, Loss: 0.4602852761745453\n",
            "Predicted string: ihello\n",
            "Epoch: 85, Loss: 0.46013060212135315\n",
            "Predicted string: ihello\n",
            "Epoch: 86, Loss: 0.45991578698158264\n",
            "Predicted string: ihello\n",
            "Epoch: 87, Loss: 0.4597570598125458\n",
            "Predicted string: ihello\n",
            "Epoch: 88, Loss: 0.459617018699646\n",
            "Predicted string: ihello\n",
            "Epoch: 89, Loss: 0.45942071080207825\n",
            "Predicted string: ihello\n",
            "Epoch: 90, Loss: 0.4592645466327667\n",
            "Predicted string: ihello\n",
            "Epoch: 91, Loss: 0.4591297209262848\n",
            "Predicted string: ihello\n",
            "Epoch: 92, Loss: 0.458958238363266\n",
            "Predicted string: ihello\n",
            "Epoch: 93, Loss: 0.45880746841430664\n",
            "Predicted string: ihello\n",
            "Epoch: 94, Loss: 0.4586833417415619\n",
            "Predicted string: ihello\n",
            "Epoch: 95, Loss: 0.4585299491882324\n",
            "Predicted string: ihello\n",
            "Epoch: 96, Loss: 0.4583899974822998\n",
            "Predicted string: ihello\n",
            "Epoch: 97, Loss: 0.4582701623439789\n",
            "Predicted string: ihello\n",
            "Epoch: 98, Loss: 0.4581303596496582\n",
            "Predicted string: ihello\n",
            "Epoch: 99, Loss: 0.4579961597919464\n",
            "Predicted string: ihello\n",
            "Epoch: 100, Loss: 0.4578794538974762\n",
            "Predicted string: ihello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3-EUDs71iKrm"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}