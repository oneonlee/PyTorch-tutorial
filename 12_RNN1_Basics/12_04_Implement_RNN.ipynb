{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture 12: RNN1 - Basics\n",
        "## Exercise 12-4: Implement RNN"
      ],
      "metadata": {
        "id": "3f7WrohgRPr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "LxKQHEZdS7pG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "# reproducibility\n",
        "torch.manual_seed(777)\n",
        "if device =='cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IxYkVqqdOWe",
        "outputId": "bf91c0e5-7ccc-4e4a-e270-d8bc8bd94f57"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (1) Data preparation"
      ],
      "metadata": {
        "id": "ka31MQ9NSQdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx2char = ['h', 'i', 'e', 'l', 'o']\n",
        "\n",
        "# Teach \"hihell\" -> \"ihello\"\n",
        "x_data = [[0, 1, 0, 2, 3, 3]] # \"hihell\"\n",
        "one_hot_lookup = [[[1, 0, 0, 0, 0],  # 0\n",
        "                   [0, 1, 0, 0, 0],  # 1\n",
        "                   [0, 0, 1, 0, 0],  # 2\n",
        "                   [0, 0, 0, 1, 0],  # 3\n",
        "                   [0, 0, 0, 0, 1]]] # 4\n",
        "\n",
        "y_data = [1, 0, 2, 3, 3, 4] # \"ihello\"\n",
        "x_one_hot = [[one_hot_lookup[0][x] for x in x_data[0]]]\n",
        "\n",
        "# As we have one batch of samples, we will change them to variables only once\n",
        "inputs = Variable(torch.Tensor(x_one_hot)).to(device)\n",
        "labels = Variable(torch.LongTensor(y_data)).to(device)"
      ],
      "metadata": {
        "id": "FXdds3UMRPd7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-RmAZaZjZxM",
        "outputId": "8c6e399c-db90-4583-b81e-1cc6bbeb2cd2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[[1, 0, 0, 0, 0],\n",
              "  [0, 1, 0, 0, 0],\n",
              "  [1, 0, 0, 0, 0],\n",
              "  [0, 0, 1, 0, 0],\n",
              "  [0, 0, 0, 1, 0],\n",
              "  [0, 0, 0, 1, 0]]]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (2) Parameters"
      ],
      "metadata": {
        "id": "1rsR4EZHSa9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "\n",
        "num_classes = 5\n",
        "input_size = 5      # one-hot size\n",
        "hidden_size = 5     # ouput from the LSTM. 5 to directly predict one-hot\n",
        "batch_size = 1      # one sentence\n",
        "output_size = 6     # |ihello| == 6\n",
        "num_layers = 1      # one-layer rnn"
      ],
      "metadata": {
        "id": "ZLGsp7ZzSa2P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (3) Our model"
      ],
      "metadata": {
        "id": "4_maaxIDS1ER"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "메모리 셀에서 은닉 상태를 계산하는 식을 다음과 같이 정의하였음\n",
        "\n",
        "$a_{t} = Ux_{t} + Wh_{t−1} + b$<br>\n",
        "$h_{t} = \\tanh{(a_{t})} = \\tanh{(Ux_{t} + Wh_{t−1} + b)}$<br>\n",
        "$o_{t} = Vh_{t} + c$<br>\n",
        "$\\hat{y_{t}}=\\textrm{softmax}(o_{t})$<br>\n",
        "\n"
      ],
      "metadata": {
        "id": "c3BtQF6eO_h-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNcell(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(RNNcell, self).__init__()\n",
        "\n",
        "        # self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.U = nn.Linear(hidden_size, input_size, bias=True)  # hidden to input (128, 24), bias:b1\n",
        "        self.W = nn.Linear(hidden_size, hidden_size, bias=True) # hidden to hidden (128, 128), bias:b2\n",
        "        self.V = nn.Linear(input_size, hidden_size, bias=True)  # input to hidden (24, 128), bias:c\n",
        "    \n",
        "        # self.reset_parameters()\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        std = 1.0 / np.sqrt(self.hidden_size)\n",
        "\n",
        "        # Initialize each parameter with numbers sampled from the continuous uniform distribution\n",
        "        for parameter in self.parameters():\n",
        "            # type(parameter.data) : Tensor\n",
        "            parameter.data.uniform_(-std, std)\n",
        "\n",
        "\n",
        "    def forward(self, x_t, h_prev):\n",
        "        a_t = self.U(x_t) + self.W(h_prev) # U * x_t + W * h_(t-1) + b\n",
        "        h_t = torch.tanh(a_t) # tanh{U * x_t + W * h_(t-1) + b}\n",
        "        o_t = self.V(h_t) # V * h_t + c\n",
        "\n",
        "        return o_t, h_t # out, hidden\n",
        "\n",
        "\n",
        "class VanillaRNN(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_classes, num_layers=1):\n",
        "        super(VanillaRNN, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_classes = num_classes\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.rnn = RNNcell(input_size=input_size, hidden_size=hidden_size)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_0 = self.init_hidden(x)\n",
        "\n",
        "        # Reshape input\n",
        "        x.view(x.size(0), self.output_size, self.input_size)\n",
        "\n",
        "        # Propagate input through RNN\n",
        "        # Input: (batch, seq_len, input_size)\n",
        "        # h_0: (num_layers * num_directions, batch, hidden_size)\n",
        "\n",
        "        out, hidden = self.rnn(x, h_0)\n",
        "        out = out.view(-1, num_classes)\n",
        "        return out\n",
        "\n",
        "\n",
        "    def init_hidden(self, x):\n",
        "        # Initialize hidden and cell states\n",
        "        return Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device)"
      ],
      "metadata": {
        "id": "_bmv-dhZSSel"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNfromPyTorch(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_classes, num_layers=1):\n",
        "        super(RNNfromPyTorch, self).__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.num_layers = num_layers\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.rnn = nn.RNN(input_size=5, hidden_size=5, batch_first=True)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_0 = self.init_hidden(x)\n",
        "\n",
        "        # Reshape input\n",
        "        x.view(x.size(0), self.output_size, self.input_size)\n",
        "\n",
        "        # Propagate input through RNN\n",
        "        # Input: (batch, seq_len, input_size)\n",
        "        # h_0: (num_layers * num_directions, batch, hidden_size)\n",
        "\n",
        "        out, hidden = self.rnn(x, h_0)\n",
        "        out = out.view(-1, num_classes)\n",
        "        return out\n",
        "\n",
        "        \n",
        "    def init_hidden(self, x):\n",
        "        # Initialize hidden and cell states\n",
        "        # (num_layers * num_directions, batch, hidden_size) for batch_first=True\n",
        "        return Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device)"
      ],
      "metadata": {
        "id": "qcEzo3xLpExW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (4) Loss & Training"
      ],
      "metadata": {
        "id": "jihOCG9hUHpp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VanillaRNN"
      ],
      "metadata": {
        "id": "tsLBOySDt8tY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ln67bq8LN5X",
        "outputId": "48c2aab5-77ad-4c89-ed5a-a4d0b275d385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VanillaRNN(\n",
            "  (rnn): RNNcell(\n",
            "    (U): Linear(in_features=5, out_features=5, bias=True)\n",
            "    (W): Linear(in_features=5, out_features=5, bias=True)\n",
            "    (V): Linear(in_features=5, out_features=5, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Instantiate RNN model\n",
        "model = VanillaRNN(input_size, hidden_size, output_size, num_classes, num_layers).to(device)\n",
        "# model = RNNfromPyTorch(input_size, hidden_size, output_size, num_classes, num_layers).to(device)\n",
        "print(model)\n",
        "\n",
        "# Set loss and optimizer function\n",
        "# CrossEntropyLoss = LogSoftmax + NLLLoss\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "for epoch in range(1, epochs + 1):\n",
        "    outputs = model(inputs).to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    _, idx = outputs.cpu().max(1)\n",
        "    idx = idx.data.numpy()\n",
        "    result_str = \"\".join([idx2char[c] for c in idx.squeeze()])\n",
        "    print(f\"Epoch: {epoch}, Loss: {loss.data.item()}\")\n",
        "    print(f\"Predicted string: {result_str}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RX8V5XGHUexi",
        "outputId": "6f93c075-eeaa-48ab-de11-f822b11f5181"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 1.6119270324707031\n",
            "Predicted string: ololll\n",
            "Epoch: 2, Loss: 1.457548975944519\n",
            "Predicted string: llllll\n",
            "Epoch: 3, Loss: 1.3519129753112793\n",
            "Predicted string: llllll\n",
            "Epoch: 4, Loss: 1.2186530828475952\n",
            "Predicted string: llllll\n",
            "Epoch: 5, Loss: 1.0769691467285156\n",
            "Predicted string: elelll\n",
            "Epoch: 6, Loss: 0.970247209072113\n",
            "Predicted string: eheloo\n",
            "Epoch: 7, Loss: 0.8818891644477844\n",
            "Predicted string: eheloo\n",
            "Epoch: 8, Loss: 0.7949978709220886\n",
            "Predicted string: ihiloo\n",
            "Epoch: 9, Loss: 0.7192606329917908\n",
            "Predicted string: ihiloo\n",
            "Epoch: 10, Loss: 0.6587330102920532\n",
            "Predicted string: ihilll\n",
            "Epoch: 11, Loss: 0.6083053350448608\n",
            "Predicted string: ihilll\n",
            "Epoch: 12, Loss: 0.5648816227912903\n",
            "Predicted string: ihilll\n",
            "Epoch: 13, Loss: 0.5310947299003601\n",
            "Predicted string: eheloo\n",
            "Epoch: 14, Loss: 0.5079692006111145\n",
            "Predicted string: eheloo\n",
            "Epoch: 15, Loss: 0.49220970273017883\n",
            "Predicted string: eheloo\n",
            "Epoch: 16, Loss: 0.4814983308315277\n",
            "Predicted string: eheloo\n",
            "Epoch: 17, Loss: 0.4756647050380707\n",
            "Predicted string: ehelll\n",
            "Epoch: 18, Loss: 0.4725077152252197\n",
            "Predicted string: ihilll\n",
            "Epoch: 19, Loss: 0.4694531261920929\n",
            "Predicted string: ihilll\n",
            "Epoch: 20, Loss: 0.46759411692619324\n",
            "Predicted string: ihiloo\n",
            "Epoch: 21, Loss: 0.46688568592071533\n",
            "Predicted string: ihiloo\n",
            "Epoch: 22, Loss: 0.46566852927207947\n",
            "Predicted string: eheloo\n",
            "Epoch: 23, Loss: 0.465037077665329\n",
            "Predicted string: ehelll\n",
            "Epoch: 24, Loss: 0.46505579352378845\n",
            "Predicted string: ehelll\n",
            "Epoch: 25, Loss: 0.4641759693622589\n",
            "Predicted string: ehelll\n",
            "Epoch: 26, Loss: 0.46397027373313904\n",
            "Predicted string: ihiloo\n",
            "Epoch: 27, Loss: 0.46402156352996826\n",
            "Predicted string: ihiloo\n",
            "Epoch: 28, Loss: 0.46347275376319885\n",
            "Predicted string: ihiloo\n",
            "Epoch: 29, Loss: 0.4635739326477051\n",
            "Predicted string: ihilll\n",
            "Epoch: 30, Loss: 0.46331891417503357\n",
            "Predicted string: ehelll\n",
            "Epoch: 31, Loss: 0.46311259269714355\n",
            "Predicted string: eheloo\n",
            "Epoch: 32, Loss: 0.46327900886535645\n",
            "Predicted string: eheloo\n",
            "Epoch: 33, Loss: 0.46291598677635193\n",
            "Predicted string: eheloo\n",
            "Epoch: 34, Loss: 0.46301090717315674\n",
            "Predicted string: ehelll\n",
            "Epoch: 35, Loss: 0.462888240814209\n",
            "Predicted string: ihilll\n",
            "Epoch: 36, Loss: 0.46281638741493225\n",
            "Predicted string: ihiloo\n",
            "Epoch: 37, Loss: 0.4628692865371704\n",
            "Predicted string: ihiloo\n",
            "Epoch: 38, Loss: 0.4626542031764984\n",
            "Predicted string: ihilll\n",
            "Epoch: 39, Loss: 0.4627879858016968\n",
            "Predicted string: ehelll\n",
            "Epoch: 40, Loss: 0.4626331627368927\n",
            "Predicted string: ehelll\n",
            "Epoch: 41, Loss: 0.4626830518245697\n",
            "Predicted string: eheloo\n",
            "Epoch: 42, Loss: 0.46260273456573486\n",
            "Predicted string: ihiloo\n",
            "Epoch: 43, Loss: 0.46259376406669617\n",
            "Predicted string: ihilll\n",
            "Epoch: 44, Loss: 0.46260491013526917\n",
            "Predicted string: ihilll\n",
            "Epoch: 45, Loss: 0.46252670884132385\n",
            "Predicted string: ihiloo\n",
            "Epoch: 46, Loss: 0.46256911754608154\n",
            "Predicted string: eheloo\n",
            "Epoch: 47, Loss: 0.4624950587749481\n",
            "Predicted string: ehelll\n",
            "Epoch: 48, Loss: 0.46254763007164\n",
            "Predicted string: ehelll\n",
            "Epoch: 49, Loss: 0.46246337890625\n",
            "Predicted string: ehelll\n",
            "Epoch: 50, Loss: 0.4625132083892822\n",
            "Predicted string: ihiloo\n",
            "Epoch: 51, Loss: 0.4624563157558441\n",
            "Predicted string: ihiloo\n",
            "Epoch: 52, Loss: 0.4624859094619751\n",
            "Predicted string: ihilll\n",
            "Epoch: 53, Loss: 0.4624370038509369\n",
            "Predicted string: ehelll\n",
            "Epoch: 54, Loss: 0.46246659755706787\n",
            "Predicted string: eheloo\n",
            "Epoch: 55, Loss: 0.46242985129356384\n",
            "Predicted string: eheloo\n",
            "Epoch: 56, Loss: 0.46244391798973083\n",
            "Predicted string: ehelll\n",
            "Epoch: 57, Loss: 0.46241864562034607\n",
            "Predicted string: ihilll\n",
            "Epoch: 58, Loss: 0.46243342757225037\n",
            "Predicted string: ihiloo\n",
            "Epoch: 59, Loss: 0.46240711212158203\n",
            "Predicted string: ihiloo\n",
            "Epoch: 60, Loss: 0.46241965889930725\n",
            "Predicted string: ehelll\n",
            "Epoch: 61, Loss: 0.4624009430408478\n",
            "Predicted string: ehelll\n",
            "Epoch: 62, Loss: 0.462409645318985\n",
            "Predicted string: eheloo\n",
            "Epoch: 63, Loss: 0.46239081025123596\n",
            "Predicted string: ihiloo\n",
            "Epoch: 64, Loss: 0.4624028205871582\n",
            "Predicted string: ihilll\n",
            "Epoch: 65, Loss: 0.46238449215888977\n",
            "Predicted string: ihilll\n",
            "Epoch: 66, Loss: 0.4623931348323822\n",
            "Predicted string: eheloo\n",
            "Epoch: 67, Loss: 0.4623798131942749\n",
            "Predicted string: ehelll\n",
            "Epoch: 68, Loss: 0.46238648891448975\n",
            "Predicted string: ehelll\n",
            "Epoch: 69, Loss: 0.4623740613460541\n",
            "Predicted string: ihiloo\n",
            "Epoch: 70, Loss: 0.46237948536872864\n",
            "Predicted string: ihiloo\n",
            "Epoch: 71, Loss: 0.4623713493347168\n",
            "Predicted string: ihilll\n",
            "Epoch: 72, Loss: 0.46237143874168396\n",
            "Predicted string: ehelll\n",
            "Epoch: 73, Loss: 0.4623687267303467\n",
            "Predicted string: eheloo\n",
            "Epoch: 74, Loss: 0.4623655080795288\n",
            "Predicted string: eheloo\n",
            "Epoch: 75, Loss: 0.46236512064933777\n",
            "Predicted string: ihilll\n",
            "Epoch: 76, Loss: 0.4623602628707886\n",
            "Predicted string: ihilll\n",
            "Epoch: 77, Loss: 0.46236202120780945\n",
            "Predicted string: ihiloo\n",
            "Epoch: 78, Loss: 0.46235576272010803\n",
            "Predicted string: ehelll\n",
            "Epoch: 79, Loss: 0.462357759475708\n",
            "Predicted string: ehelll\n",
            "Epoch: 80, Loss: 0.46235331892967224\n",
            "Predicted string: eheloo\n",
            "Epoch: 81, Loss: 0.4623524844646454\n",
            "Predicted string: ihiloo\n",
            "Epoch: 82, Loss: 0.4623512327671051\n",
            "Predicted string: ihilll\n",
            "Epoch: 83, Loss: 0.4623481333255768\n",
            "Predicted string: ihilll\n",
            "Epoch: 84, Loss: 0.4623483121395111\n",
            "Predicted string: eheloo\n",
            "Epoch: 85, Loss: 0.4623449742794037\n",
            "Predicted string: ehelll\n",
            "Epoch: 86, Loss: 0.4623447358608246\n",
            "Predicted string: ehelll\n",
            "Epoch: 87, Loss: 0.46234241127967834\n",
            "Predicted string: ihiloo\n",
            "Epoch: 88, Loss: 0.46234098076820374\n",
            "Predicted string: ihiloo\n",
            "Epoch: 89, Loss: 0.4623401165008545\n",
            "Predicted string: ihilll\n",
            "Epoch: 90, Loss: 0.4623376131057739\n",
            "Predicted string: ehelll\n",
            "Epoch: 91, Loss: 0.46233734488487244\n",
            "Predicted string: eheloo\n",
            "Epoch: 92, Loss: 0.46233510971069336\n",
            "Predicted string: ihilll\n",
            "Epoch: 93, Loss: 0.46233394742012024\n",
            "Predicted string: ihilll\n",
            "Epoch: 94, Loss: 0.462333083152771\n",
            "Predicted string: ihiloo\n",
            "Epoch: 95, Loss: 0.46233105659484863\n",
            "Predicted string: ehelll\n",
            "Epoch: 96, Loss: 0.46233034133911133\n",
            "Predicted string: ehelll\n",
            "Epoch: 97, Loss: 0.4623287618160248\n",
            "Predicted string: eheloo\n",
            "Epoch: 98, Loss: 0.4623272716999054\n",
            "Predicted string: ihiloo\n",
            "Epoch: 99, Loss: 0.4623265266418457\n",
            "Predicted string: ihilll\n",
            "Epoch: 100, Loss: 0.46232473850250244\n",
            "Predicted string: ihiloo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNNfromPyTorch"
      ],
      "metadata": {
        "id": "l0j7axTTuBGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate RNN model\n",
        "model = RNNfromPyTorch(input_size, hidden_size, output_size, num_classes, num_layers).to(device)\n",
        "print(model)\n",
        "\n",
        "# Set loss and optimizer function\n",
        "# CrossEntropyLoss = LogSoftmax + NLLLoss\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-us7K-F_qvdu",
        "outputId": "bee55420-a0cc-4566-9f9d-c11dafa5f34d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNNfromPyTorch(\n",
            "  (rnn): RNN(5, 5, batch_first=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "for epoch in range(1, epochs + 1):\n",
        "    outputs = model(inputs).to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    _, idx = outputs.cpu().max(1)\n",
        "    idx = idx.data.numpy()\n",
        "    result_str = \"\".join([idx2char[c] for c in idx.squeeze()])\n",
        "    print(f\"Epoch: {epoch}, Loss: {loss.data.item()}\")\n",
        "    print(f\"Predicted string: {result_str}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q48XEyIuC4v",
        "outputId": "650450c0-dd8f-42f3-84c6-58329f238b36"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 1.7460657358169556\n",
            "Predicted string: iilihh\n",
            "Epoch: 2, Loss: 1.5093475580215454\n",
            "Predicted string: iillll\n",
            "Epoch: 3, Loss: 1.3484634160995483\n",
            "Predicted string: illlll\n",
            "Epoch: 4, Loss: 1.23129141330719\n",
            "Predicted string: illlll\n",
            "Epoch: 5, Loss: 1.134954571723938\n",
            "Predicted string: ihllll\n",
            "Epoch: 6, Loss: 1.0518126487731934\n",
            "Predicted string: ihlllo\n",
            "Epoch: 7, Loss: 0.9598258137702942\n",
            "Predicted string: ihlllo\n",
            "Epoch: 8, Loss: 0.9119052290916443\n",
            "Predicted string: ihehll\n",
            "Epoch: 9, Loss: 0.8687078952789307\n",
            "Predicted string: ihehll\n",
            "Epoch: 10, Loss: 0.7842835783958435\n",
            "Predicted string: ihelll\n",
            "Epoch: 11, Loss: 0.730978786945343\n",
            "Predicted string: ihelll\n",
            "Epoch: 12, Loss: 0.7004899978637695\n",
            "Predicted string: ihelll\n",
            "Epoch: 13, Loss: 0.6720936894416809\n",
            "Predicted string: ihelll\n",
            "Epoch: 14, Loss: 0.6466363668441772\n",
            "Predicted string: ihelll\n",
            "Epoch: 15, Loss: 0.625917911529541\n",
            "Predicted string: ihelll\n",
            "Epoch: 16, Loss: 0.6092942357063293\n",
            "Predicted string: ihelll\n",
            "Epoch: 17, Loss: 0.5957011580467224\n",
            "Predicted string: ihelll\n",
            "Epoch: 18, Loss: 0.5846253037452698\n",
            "Predicted string: ihelll\n",
            "Epoch: 19, Loss: 0.5764088034629822\n",
            "Predicted string: ihelll\n",
            "Epoch: 20, Loss: 0.5707210302352905\n",
            "Predicted string: ihelll\n",
            "Epoch: 21, Loss: 0.5652255415916443\n",
            "Predicted string: ihelll\n",
            "Epoch: 22, Loss: 0.560267448425293\n",
            "Predicted string: ihelll\n",
            "Epoch: 23, Loss: 0.5567342638969421\n",
            "Predicted string: ihelll\n",
            "Epoch: 24, Loss: 0.5533877611160278\n",
            "Predicted string: ihelll\n",
            "Epoch: 25, Loss: 0.5500913262367249\n",
            "Predicted string: ihelll\n",
            "Epoch: 26, Loss: 0.5477566123008728\n",
            "Predicted string: ihelll\n",
            "Epoch: 27, Loss: 0.5457320809364319\n",
            "Predicted string: ihelll\n",
            "Epoch: 28, Loss: 0.5434595346450806\n",
            "Predicted string: ihelll\n",
            "Epoch: 29, Loss: 0.5419086217880249\n",
            "Predicted string: ihelll\n",
            "Epoch: 30, Loss: 0.5405997037887573\n",
            "Predicted string: ihelll\n",
            "Epoch: 31, Loss: 0.5391263961791992\n",
            "Predicted string: ihelll\n",
            "Epoch: 32, Loss: 0.5380339622497559\n",
            "Predicted string: ihelll\n",
            "Epoch: 33, Loss: 0.5372135639190674\n",
            "Predicted string: ihelll\n",
            "Epoch: 34, Loss: 0.5361545085906982\n",
            "Predicted string: ihelll\n",
            "Epoch: 35, Loss: 0.5354092121124268\n",
            "Predicted string: ihelll\n",
            "Epoch: 36, Loss: 0.5348079204559326\n",
            "Predicted string: ihelll\n",
            "Epoch: 37, Loss: 0.5340566039085388\n",
            "Predicted string: ihelll\n",
            "Epoch: 38, Loss: 0.5334974527359009\n",
            "Predicted string: ihelll\n",
            "Epoch: 39, Loss: 0.5330565571784973\n",
            "Predicted string: ihelll\n",
            "Epoch: 40, Loss: 0.5324684977531433\n",
            "Predicted string: ihelll\n",
            "Epoch: 41, Loss: 0.5320668816566467\n",
            "Predicted string: ihelll\n",
            "Epoch: 42, Loss: 0.5316939353942871\n",
            "Predicted string: ihelll\n",
            "Epoch: 43, Loss: 0.5312384963035583\n",
            "Predicted string: ihelll\n",
            "Epoch: 44, Loss: 0.5309264659881592\n",
            "Predicted string: ihelll\n",
            "Epoch: 45, Loss: 0.5306049585342407\n",
            "Predicted string: ihelll\n",
            "Epoch: 46, Loss: 0.5302416086196899\n",
            "Predicted string: ihelll\n",
            "Epoch: 47, Loss: 0.5299946665763855\n",
            "Predicted string: ihelll\n",
            "Epoch: 48, Loss: 0.5297025442123413\n",
            "Predicted string: ihelll\n",
            "Epoch: 49, Loss: 0.5294148921966553\n",
            "Predicted string: ihelll\n",
            "Epoch: 50, Loss: 0.5292048454284668\n",
            "Predicted string: ihelll\n",
            "Epoch: 51, Loss: 0.5289372801780701\n",
            "Predicted string: ihelll\n",
            "Epoch: 52, Loss: 0.5287143588066101\n",
            "Predicted string: ihelll\n",
            "Epoch: 53, Loss: 0.5285158753395081\n",
            "Predicted string: ihelll\n",
            "Epoch: 54, Loss: 0.5282822251319885\n",
            "Predicted string: ihelll\n",
            "Epoch: 55, Loss: 0.5281004905700684\n",
            "Predicted string: ihelll\n",
            "Epoch: 56, Loss: 0.5279080271720886\n",
            "Predicted string: ihelll\n",
            "Epoch: 57, Loss: 0.5277110934257507\n",
            "Predicted string: ihelll\n",
            "Epoch: 58, Loss: 0.5275510549545288\n",
            "Predicted string: ihelll\n",
            "Epoch: 59, Loss: 0.5273668766021729\n",
            "Predicted string: ihelll\n",
            "Epoch: 60, Loss: 0.5272039175033569\n",
            "Predicted string: ihelll\n",
            "Epoch: 61, Loss: 0.5270504951477051\n",
            "Predicted string: ihelll\n",
            "Epoch: 62, Loss: 0.5268834233283997\n",
            "Predicted string: ihelll\n",
            "Epoch: 63, Loss: 0.5267431139945984\n",
            "Predicted string: ihelll\n",
            "Epoch: 64, Loss: 0.5265917181968689\n",
            "Predicted string: ihelll\n",
            "Epoch: 65, Loss: 0.5264479517936707\n",
            "Predicted string: ihelll\n",
            "Epoch: 66, Loss: 0.5263156294822693\n",
            "Predicted string: ihelll\n",
            "Epoch: 67, Loss: 0.5261731743812561\n",
            "Predicted string: ihelll\n",
            "Epoch: 68, Loss: 0.5260476469993591\n",
            "Predicted string: ihelll\n",
            "Epoch: 69, Loss: 0.5259169340133667\n",
            "Predicted string: ihelll\n",
            "Epoch: 70, Loss: 0.5257906317710876\n",
            "Predicted string: ihelll\n",
            "Epoch: 71, Loss: 0.5256721377372742\n",
            "Predicted string: ihelll\n",
            "Epoch: 72, Loss: 0.5255480408668518\n",
            "Predicted string: ihelll\n",
            "Epoch: 73, Loss: 0.5254349112510681\n",
            "Predicted string: ihelll\n",
            "Epoch: 74, Loss: 0.5253185033798218\n",
            "Predicted string: ihelll\n",
            "Epoch: 75, Loss: 0.5252065062522888\n",
            "Predicted string: ihelll\n",
            "Epoch: 76, Loss: 0.5250985026359558\n",
            "Predicted string: ihelll\n",
            "Epoch: 77, Loss: 0.5249884128570557\n",
            "Predicted string: ihelll\n",
            "Epoch: 78, Loss: 0.5248854756355286\n",
            "Predicted string: ihelll\n",
            "Epoch: 79, Loss: 0.5247802734375\n",
            "Predicted string: ihelll\n",
            "Epoch: 80, Loss: 0.5246797204017639\n",
            "Predicted string: ihelll\n",
            "Epoch: 81, Loss: 0.5245802998542786\n",
            "Predicted string: ihelll\n",
            "Epoch: 82, Loss: 0.5244815349578857\n",
            "Predicted string: ihelll\n",
            "Epoch: 83, Loss: 0.5243868231773376\n",
            "Predicted string: ihelll\n",
            "Epoch: 84, Loss: 0.5242910981178284\n",
            "Predicted string: ihelll\n",
            "Epoch: 85, Loss: 0.5241994857788086\n",
            "Predicted string: ihelll\n",
            "Epoch: 86, Loss: 0.5241076350212097\n",
            "Predicted string: ihelll\n",
            "Epoch: 87, Loss: 0.5240181088447571\n",
            "Predicted string: ihelll\n",
            "Epoch: 88, Loss: 0.5239301919937134\n",
            "Predicted string: ihelll\n",
            "Epoch: 89, Loss: 0.5238428115844727\n",
            "Predicted string: ihelll\n",
            "Epoch: 90, Loss: 0.5237582325935364\n",
            "Predicted string: ihelll\n",
            "Epoch: 91, Loss: 0.5236733555793762\n",
            "Predicted string: ihelll\n",
            "Epoch: 92, Loss: 0.523591160774231\n",
            "Predicted string: ihelll\n",
            "Epoch: 93, Loss: 0.5235093235969543\n",
            "Predicted string: ihelll\n",
            "Epoch: 94, Loss: 0.5234292149543762\n",
            "Predicted string: ihelll\n",
            "Epoch: 95, Loss: 0.523350179195404\n",
            "Predicted string: ihelll\n",
            "Epoch: 96, Loss: 0.5232720375061035\n",
            "Predicted string: ihelll\n",
            "Epoch: 97, Loss: 0.5231955647468567\n",
            "Predicted string: ihelll\n",
            "Epoch: 98, Loss: 0.5231195688247681\n",
            "Predicted string: ihelll\n",
            "Epoch: 99, Loss: 0.5230453610420227\n",
            "Predicted string: ihelll\n",
            "Epoch: 100, Loss: 0.5229714512825012\n",
            "Predicted string: ihelll\n"
          ]
        }
      ]
    }
  ]
}