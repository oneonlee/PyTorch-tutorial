{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture 12: RNN1 - Basics\n",
        "## Exercise 12-3: Combine RNN+Linear using embedding"
      ],
      "metadata": {
        "id": "Bdxjll8ml7ou"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J2iwqm95kZPW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import sys\n",
        "\n",
        "torch.manual_seed(777)  # reproducibility\n",
        "\n",
        "idx2char = ['h', 'i', 'e', 'l', 'o']\n",
        "\n",
        "# Teach \"hihell\" -> \"ihello\"\n",
        "x_data = [[0, 1, 0, 2, 3, 3]] # \"hihell\"\n",
        "one_hot_lookup = [[[1, 0, 0, 0, 0],  # 0\n",
        "                   [0, 1, 0, 0, 0],  # 1\n",
        "                   [0, 0, 1, 0, 0],  # 2\n",
        "                   [0, 0, 0, 1, 0],  # 3\n",
        "                   [0, 0, 0, 0, 1]]] # 4\n",
        "\n",
        "y_data = [1, 0, 2, 3, 3, 4] # \"ihello\"\n",
        "x_one_hot = [[one_hot_lookup[0][x] for x in x_data[0]]]\n",
        "\n",
        "# As we have one batch of samples, we will change them to variables only once\n",
        "inputs = Variable(torch.Tensor(x_one_hot))\n",
        "labels = Variable(torch.LongTensor(y_data))\n",
        "\n",
        "num_classes = 5\n",
        "input_size = 5      # one-hot size\n",
        "hidden_size = 5     # ouput from the LSTM. 5 to directly predict one-hot\n",
        "batch_size = 1      # one sentence\n",
        "sequence_length = 6 # |ihello| == 6\n",
        "num_layers = 1      # one-layer rnn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CombinedModel(nn.Module):\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
        "        super(CombinedModel, self).__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.sequence_length = sequence_length\n",
        "\n",
        "        self.rnn = nn.RNN(input_size=self.input_size,\n",
        "                          hidden_size=self.hidden_size, batch_first=True)\n",
        "        self.linear = nn.Linear(self.hidden_size, self.input_size)\n",
        "        self.embeddings = nn.Embedding(num_embeddings=self.input_size, \n",
        "                                       embedding_dim=self.hidden_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        emb = self.embeddings(x.long())\n",
        "\n",
        "        hidden = self.init_hidden(x)\n",
        "        \n",
        "        # Reshape input in (batch_size, sequence_length, input_size)\n",
        "        x.view(x.size(0), self.sequence_length, self.input_size)\n",
        "\n",
        "        # Propagate input through RNN\n",
        "        # Input: (batch, seq_len, input_size)\n",
        "        # hidden: (num_layers * num_directions, batch, hidden_size)\n",
        "        x, hidden = self.rnn(x, hidden)\n",
        "        out = self.linear(x)\n",
        "        out = out.view(-1, num_classes)\n",
        "        return out\n",
        "\n",
        "    def init_hidden(self, x):\n",
        "        # Initialize hidden and cell states\n",
        "        # (num_layers * num_directions, batch, hidden_size) for batch_first=True\n",
        "        return Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))"
      ],
      "metadata": {
        "id": "d1dOUjFrmMvT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate RNN model\n",
        "model = CombinedModel(num_classes, input_size, hidden_size, num_layers)\n",
        "print(model)\n",
        "\n",
        "# Set loss and optimizer function\n",
        "# CrossEntropyLoss = LogSoftmax + NLLLoss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcUPQAv_nmOV",
        "outputId": "75d2ffb0-5db2-4aa1-a4ac-b677552c4bc6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CombinedModel(\n",
            "  (rnn): RNN(5, 5, batch_first=True)\n",
            "  (linear): Linear(in_features=5, out_features=5, bias=True)\n",
            "  (embeddings): Embedding(5, 5)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "epochs = 100\n",
        "for epoch in range(1, epochs + 1):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    _, idx = outputs.max(1)\n",
        "    idx = idx.data.numpy()\n",
        "    result_str = \"\".join([idx2char[c] for c in idx.squeeze()])\n",
        "    print(f\"Epoch: {epoch}, Loss: {loss.data.item()}\")\n",
        "    print(f\"Predicted string: {result_str}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ojcK6xHnpzz",
        "outputId": "beda85aa-7516-449d-a309-522053070cbf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 1.6452089548110962\n",
            "Predicted string: oooooo\n",
            "Epoch: 2, Loss: 1.4475892782211304\n",
            "Predicted string: llllll\n",
            "Epoch: 3, Loss: 1.3083527088165283\n",
            "Predicted string: llllll\n",
            "Epoch: 4, Loss: 1.1435742378234863\n",
            "Predicted string: illlll\n",
            "Epoch: 5, Loss: 0.9536089897155762\n",
            "Predicted string: ilello\n",
            "Epoch: 6, Loss: 0.7698957324028015\n",
            "Predicted string: ihello\n",
            "Epoch: 7, Loss: 0.611672580242157\n",
            "Predicted string: ihello\n",
            "Epoch: 8, Loss: 0.48554909229278564\n",
            "Predicted string: ihello\n",
            "Epoch: 9, Loss: 0.3739349842071533\n",
            "Predicted string: ihello\n",
            "Epoch: 10, Loss: 0.2720254957675934\n",
            "Predicted string: ihello\n",
            "Epoch: 11, Loss: 0.1990143209695816\n",
            "Predicted string: ihello\n",
            "Epoch: 12, Loss: 0.14738725125789642\n",
            "Predicted string: ihello\n",
            "Epoch: 13, Loss: 0.10521908849477768\n",
            "Predicted string: ihello\n",
            "Epoch: 14, Loss: 0.07793185859918594\n",
            "Predicted string: ihello\n",
            "Epoch: 15, Loss: 0.05503419041633606\n",
            "Predicted string: ihello\n",
            "Epoch: 16, Loss: 0.04002940282225609\n",
            "Predicted string: ihello\n",
            "Epoch: 17, Loss: 0.031835149973630905\n",
            "Predicted string: ihello\n",
            "Epoch: 18, Loss: 0.024005508050322533\n",
            "Predicted string: ihello\n",
            "Epoch: 19, Loss: 0.017552142962813377\n",
            "Predicted string: ihello\n",
            "Epoch: 20, Loss: 0.014079111628234386\n",
            "Predicted string: ihello\n",
            "Epoch: 21, Loss: 0.012053757905960083\n",
            "Predicted string: ihello\n",
            "Epoch: 22, Loss: 0.00961331743746996\n",
            "Predicted string: ihello\n",
            "Epoch: 23, Loss: 0.007497014943510294\n",
            "Predicted string: ihello\n",
            "Epoch: 24, Loss: 0.006538995075970888\n",
            "Predicted string: ihello\n",
            "Epoch: 25, Loss: 0.0061361826956272125\n",
            "Predicted string: ihello\n",
            "Epoch: 26, Loss: 0.0049833147786557674\n",
            "Predicted string: ihello\n",
            "Epoch: 27, Loss: 0.004096610937267542\n",
            "Predicted string: ihello\n",
            "Epoch: 28, Loss: 0.0037487621884793043\n",
            "Predicted string: ihello\n",
            "Epoch: 29, Loss: 0.003580415388569236\n",
            "Predicted string: ihello\n",
            "Epoch: 30, Loss: 0.003254573093727231\n",
            "Predicted string: ihello\n",
            "Epoch: 31, Loss: 0.0028096053283661604\n",
            "Predicted string: ihello\n",
            "Epoch: 32, Loss: 0.00246264785528183\n",
            "Predicted string: ihello\n",
            "Epoch: 33, Loss: 0.0022707798052579165\n",
            "Predicted string: ihello\n",
            "Epoch: 34, Loss: 0.0021878709085285664\n",
            "Predicted string: ihello\n",
            "Epoch: 35, Loss: 0.002114807954058051\n",
            "Predicted string: ihello\n",
            "Epoch: 36, Loss: 0.0019743533339351416\n",
            "Predicted string: ihello\n",
            "Epoch: 37, Loss: 0.0018013017252087593\n",
            "Predicted string: ihello\n",
            "Epoch: 38, Loss: 0.001660704961977899\n",
            "Predicted string: ihello\n",
            "Epoch: 39, Loss: 0.001569765736348927\n",
            "Predicted string: ihello\n",
            "Epoch: 40, Loss: 0.0015153767308220267\n",
            "Predicted string: ihello\n",
            "Epoch: 41, Loss: 0.0014772526919841766\n",
            "Predicted string: ihello\n",
            "Epoch: 42, Loss: 0.0014377973275259137\n",
            "Predicted string: ihello\n",
            "Epoch: 43, Loss: 0.0013879731995984912\n",
            "Predicted string: ihello\n",
            "Epoch: 44, Loss: 0.0013298937119543552\n",
            "Predicted string: ihello\n",
            "Epoch: 45, Loss: 0.001272014807909727\n",
            "Predicted string: ihello\n",
            "Epoch: 46, Loss: 0.0012219649506732821\n",
            "Predicted string: ihello\n",
            "Epoch: 47, Loss: 0.0011833136668428779\n",
            "Predicted string: ihello\n",
            "Epoch: 48, Loss: 0.0011556058889254928\n",
            "Predicted string: ihello\n",
            "Epoch: 49, Loss: 0.001135332160629332\n",
            "Predicted string: ihello\n",
            "Epoch: 50, Loss: 0.001118109910748899\n",
            "Predicted string: ihello\n",
            "Epoch: 51, Loss: 0.0010998938232660294\n",
            "Predicted string: ihello\n",
            "Epoch: 52, Loss: 0.001078760251402855\n",
            "Predicted string: ihello\n",
            "Epoch: 53, Loss: 0.001055423286743462\n",
            "Predicted string: ihello\n",
            "Epoch: 54, Loss: 0.001032144296914339\n",
            "Predicted string: ihello\n",
            "Epoch: 55, Loss: 0.0010112047893926501\n",
            "Predicted string: ihello\n",
            "Epoch: 56, Loss: 0.000994053902104497\n",
            "Predicted string: ihello\n",
            "Epoch: 57, Loss: 0.0009805932641029358\n",
            "Predicted string: ihello\n",
            "Epoch: 58, Loss: 0.0009699904476292431\n",
            "Predicted string: ihello\n",
            "Epoch: 59, Loss: 0.0009607579559087753\n",
            "Predicted string: ihello\n",
            "Epoch: 60, Loss: 0.0009516662103123963\n",
            "Predicted string: ihello\n",
            "Epoch: 61, Loss: 0.0009418419213034213\n",
            "Predicted string: ihello\n",
            "Epoch: 62, Loss: 0.0009311660542152822\n",
            "Predicted string: ihello\n",
            "Epoch: 63, Loss: 0.0009201538632623851\n",
            "Predicted string: ihello\n",
            "Epoch: 64, Loss: 0.0009094795095734298\n",
            "Predicted string: ihello\n",
            "Epoch: 65, Loss: 0.00089985691010952\n",
            "Predicted string: ihello\n",
            "Epoch: 66, Loss: 0.0008915040525607765\n",
            "Predicted string: ihello\n",
            "Epoch: 67, Loss: 0.0008844802505336702\n",
            "Predicted string: ihello\n",
            "Epoch: 68, Loss: 0.0008783090743236244\n",
            "Predicted string: ihello\n",
            "Epoch: 69, Loss: 0.000872474629431963\n",
            "Predicted string: ihello\n",
            "Epoch: 70, Loss: 0.0008665998466312885\n",
            "Predicted string: ihello\n",
            "Epoch: 71, Loss: 0.0008604070171713829\n",
            "Predicted string: ihello\n",
            "Epoch: 72, Loss: 0.00085393589688465\n",
            "Predicted string: ihello\n",
            "Epoch: 73, Loss: 0.0008474642527289689\n",
            "Predicted string: ihello\n",
            "Epoch: 74, Loss: 0.000841190863866359\n",
            "Predicted string: ihello\n",
            "Epoch: 75, Loss: 0.0008353539160452783\n",
            "Predicted string: ihello\n",
            "Epoch: 76, Loss: 0.0008300924091599882\n",
            "Predicted string: ihello\n",
            "Epoch: 77, Loss: 0.0008251882973127067\n",
            "Predicted string: ihello\n",
            "Epoch: 78, Loss: 0.0008205423946492374\n",
            "Predicted string: ihello\n",
            "Epoch: 79, Loss: 0.0008159962599165738\n",
            "Predicted string: ihello\n",
            "Epoch: 80, Loss: 0.0008113312069326639\n",
            "Predicted string: ihello\n",
            "Epoch: 81, Loss: 0.000806646712590009\n",
            "Predicted string: ihello\n",
            "Epoch: 82, Loss: 0.0008019229280762374\n",
            "Predicted string: ihello\n",
            "Epoch: 83, Loss: 0.0007971397135406733\n",
            "Predicted string: ihello\n",
            "Epoch: 84, Loss: 0.0007924956153146923\n",
            "Predicted string: ihello\n",
            "Epoch: 85, Loss: 0.0007880895282141864\n",
            "Predicted string: ihello\n",
            "Epoch: 86, Loss: 0.0007838421151973307\n",
            "Predicted string: ihello\n",
            "Epoch: 87, Loss: 0.0007797337020747364\n",
            "Predicted string: ihello\n",
            "Epoch: 88, Loss: 0.0007757241255603731\n",
            "Predicted string: ihello\n",
            "Epoch: 89, Loss: 0.0007717739208601415\n",
            "Predicted string: ihello\n",
            "Epoch: 90, Loss: 0.0007677441462874413\n",
            "Predicted string: ihello\n",
            "Epoch: 91, Loss: 0.0007637538947165012\n",
            "Predicted string: ihello\n",
            "Epoch: 92, Loss: 0.0007597039802931249\n",
            "Predicted string: ihello\n",
            "Epoch: 93, Loss: 0.0007557531353086233\n",
            "Predicted string: ihello\n",
            "Epoch: 94, Loss: 0.0007518220809288323\n",
            "Predicted string: ihello\n",
            "Epoch: 95, Loss: 0.0007479903288185596\n",
            "Predicted string: ihello\n",
            "Epoch: 96, Loss: 0.0007441584602929652\n",
            "Predicted string: ihello\n",
            "Epoch: 97, Loss: 0.0007405054639093578\n",
            "Predicted string: ihello\n",
            "Epoch: 98, Loss: 0.000736792862880975\n",
            "Predicted string: ihello\n",
            "Epoch: 99, Loss: 0.0007331597735174\n",
            "Predicted string: ihello\n",
            "Epoch: 100, Loss: 0.0007295070099644363\n",
            "Predicted string: ihello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rcnY6Uy7p16a"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}