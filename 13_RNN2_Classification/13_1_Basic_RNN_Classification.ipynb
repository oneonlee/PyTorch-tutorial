{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture 13: RNN 2 - Classification"
      ],
      "metadata": {
        "id": "Aey7c2tfQf5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "K0szfaylQ3Du"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters and DataLoaders\n",
        "HIDDEN_SIZE = 100\n",
        "N_CHARS = 128  # ASCII\n",
        "N_CLASSES = 18"
      ],
      "metadata": {
        "id": "B0GikfZhVfha"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "        super(RNNClassifier, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Note: we run this all at once (over the whole input sequence)\n",
        "        # input : B x S.size(0) = B\n",
        "        batch_size = input.size(0)\n",
        "\n",
        "        # input : B x S --(transpose)--> S x B\n",
        "        input = input.t()\n",
        "\n",
        "        # Embedding S x B ---> S x B x I (embedding size)\n",
        "        print(f\"input : {input.size()}\")\n",
        "        embedded = self.embedding(input)\n",
        "        print(f\"embedding : {embedded.size()}\")\n",
        "\n",
        "        # Make a hidden\n",
        "        hidden = self._init_hidden(batch_size)\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        print(f\"GRU hidden output : {hidden.size()}\")\n",
        "        # Use the last layer output as FC's input\n",
        "        # No need to unpack, since we are going to use hidden\n",
        "        fc_output = self.fc(hidden)\n",
        "        print(f\"FC output : {fc_output.size()}\")\n",
        "        print()\n",
        "        \n",
        "        return fc_output\n",
        "\n",
        "    def _init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_size)\n",
        "        return Variable(hidden)"
      ],
      "metadata": {
        "id": "UN71ncpeSaip"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Help functions\n",
        "\n",
        "def str2ascii_arr(msg):\n",
        "    arr = [ord(c) for c in msg]\n",
        "    return arr, len(arr)\n",
        "\n",
        "# pad sequences and sort the tensor\n",
        "def pad_sequences(vectorized_seq, seq_lengths):\n",
        "    seq_tensor = torch.zeros((len(vectorized_seq), seq_lengths.max())).long()\n",
        "    for idx, (seq, seq_len) in enumerate(zip(vectorized_seq, seq_lengths)):\n",
        "        seq_tensor[idx, :seq_len] = torch.LongTensor(seq)\n",
        "    return seq_tensor\n",
        "\n",
        "# Create necessary variables, lengths, and target\n",
        "def make_variables(names):\n",
        "    sequence_and_length = [str2ascii_arr(name) for name in names]\n",
        "    vectorized_seqs = [sl[0] for sl in sequence_and_length]\n",
        "    seq_lengths = torch.LongTensor([sl[1] for sl in sequence_and_length])\n",
        "\n",
        "    return pad_sequences(vectorized_seqs, seq_lengths)"
      ],
      "metadata": {
        "id": "4kB6oEa-Qoot"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__==\"__main__\":\n",
        "    names = ['adylov', 'solan', 'hard', 'san']\n",
        "    classifier = RNNClassifier(N_CHARS, HIDDEN_SIZE, N_CLASSES)\n",
        "\n",
        "    for name in names:\n",
        "        arr, _ = str2ascii_arr(name)\n",
        "        inp = Variable(torch.LongTensor([arr]))\n",
        "        out = classifier(inp)\n",
        "        print(\"in\", inp.size(), \"out\", out.size())\n",
        "\n",
        "    inputs = make_variables(names)\n",
        "    out = classifier(inputs)\n",
        "    print(f\"batch in {inputs.size()}, batch out {out.size()}\") # batch in torch.Size([4, 6]), batch out torch.Size([1, 4, 18])"
      ],
      "metadata": {
        "id": "M4NTJ_8QRwr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e37a2a6-ff78-4b47-c3ed-fae446caf05b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input : torch.Size([6, 1])\n",
            "embedding : torch.Size([6, 1, 100])\n",
            "GRU hidden output : torch.Size([1, 1, 100])\n",
            "FC output : torch.Size([1, 1, 18])\n",
            "\n",
            "in torch.Size([1, 6]) out torch.Size([1, 1, 18])\n",
            "input : torch.Size([5, 1])\n",
            "embedding : torch.Size([5, 1, 100])\n",
            "GRU hidden output : torch.Size([1, 1, 100])\n",
            "FC output : torch.Size([1, 1, 18])\n",
            "\n",
            "in torch.Size([1, 5]) out torch.Size([1, 1, 18])\n",
            "input : torch.Size([4, 1])\n",
            "embedding : torch.Size([4, 1, 100])\n",
            "GRU hidden output : torch.Size([1, 1, 100])\n",
            "FC output : torch.Size([1, 1, 18])\n",
            "\n",
            "in torch.Size([1, 4]) out torch.Size([1, 1, 18])\n",
            "input : torch.Size([3, 1])\n",
            "embedding : torch.Size([3, 1, 100])\n",
            "GRU hidden output : torch.Size([1, 1, 100])\n",
            "FC output : torch.Size([1, 1, 18])\n",
            "\n",
            "in torch.Size([1, 3]) out torch.Size([1, 1, 18])\n",
            "input : torch.Size([6, 4])\n",
            "embedding : torch.Size([6, 4, 100])\n",
            "GRU hidden output : torch.Size([1, 4, 100])\n",
            "FC output : torch.Size([1, 4, 18])\n",
            "\n",
            "batch in torch.Size([4, 6]), batch out torch.Size([1, 4, 18])\n"
          ]
        }
      ]
    }
  ]
}